{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "paperback-cornwall",
   "metadata": {},
   "source": [
    "This preprocessing file cleans up the survey and reference data files and creates reference files in the resources folder for the analysis carried out in the 2020 descriptive notebook. This notebook should be run before running the 2020_descriptive notebook in order to be sure the necessary files are updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "paperback-funds",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import datetime as dt\n",
    "import math\n",
    "import json\n",
    "import csv\n",
    "\n",
    "here = os.getcwd()\n",
    "flora_h = F\"{here}/resources/reference-data/\"\n",
    "flora_h_ws = F\"{flora_h}atlasws/\"\n",
    "flora_h_55 = F\"{flora_h}atlas5x5/\"\n",
    "data_2020 = F\"{here}/resources/survey-data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "vietnamese-european",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the data files\n",
    "\n",
    "# start by organizing them into dictionaries.\n",
    "\n",
    "my_data_methods = {\"csv\":pd.read_csv}\n",
    "\n",
    "# dict for the 2020 survey data files\n",
    "d_files = {\n",
    "    \"surveys\":\"2020datasimp.csv\",\n",
    "    \"map_keys\":\"map-keys-2020.csv\",    \n",
    "}\n",
    "\n",
    "# dict for the reference files that are not Welten Sutter or Flora Helvetica 5X5 lists\n",
    "w_lists = {\n",
    "    \"list_2014\":\"BL_WL_2014_modified.csv\",\n",
    "    \"under_sampled\":\"taxa_sous_echantillonnes.csv\",\n",
    "    \"red_list\":\"CH-RLreg_Tracheophyta_2019.csv\",\n",
    "}\n",
    "\n",
    "# dict for the Welten-Sutter map reference files, downloaded from here: https://www.infoflora.ch/de/daten/artenliste-welten-sutter.html\n",
    "# all observations included in this report were conducted within one of these geographic boundaries\n",
    "\n",
    "ws_lists ={\n",
    "    \"151\":\"AtlasWS_151_Biel.csv\",\n",
    "    \"252\":\"AtlasWS_252_Erlach.csv\",\n",
    "    \"300\":\"AtlasWS_300_Aarberg.csv\",\n",
    "    \"301\":\"AtlasWS_301_Bueren.csv\",\n",
    "    \"154\":\"AtlasWS_154_Grenchen.csv\",\n",
    "    \"572\":\"AtlasWS_572_Beatenberg.csv\",\n",
    "    \"573\":\"AtlasWS_573_Interlaken.csv\",\n",
    "    \"226\":\"AtlasWS_226_Estavayer.csv\",\n",
    "    \"251\":\"AtlasWS_251_BernWest.csv\",\n",
    "    \"145\":\"AtlasWS_145_LesRangiers.csv\"\n",
    "}\n",
    "\n",
    "\n",
    "# dict for the Flora Helvetica 5x5 map reference files, downloaded from here: https://www.infoflora.ch/de/daten/artenliste-5x5-km.html\n",
    "# all observations included in this report were conducted within one of these geographic boundaries\n",
    "\n",
    "# housekeeping: 585220 is separated by \",\" not \";\" like the rest of the data sources\n",
    "df = pd.read_csv(\"resources/reference-data/atlas5x5/Atlas5x5_585_220.csv\", sep = \",\", encoding=\"utf-16\")\n",
    "df.to_csv('resources/reference-data/atlas5x5/Atlas5x5_585_220_1.csv', sep=';', encoding = \"utf-16\", index = False)\n",
    "\n",
    "fx_lists = {\n",
    "    \"585215\":\"Atlas5x5_585_215.csv\", # Ipsach, Bielersee\n",
    "    \"585220\":\"Atlas5x5_585_220_1.csv\", # Biel Stadt, Suze / Bielersee\n",
    "    \"580220\":\"Atlas5x5_580_220.csv\", # Biel Mett, Suze\n",
    "    \"580215\":\"Atlas5x5_580_215.csv\", # Port, Nidau-Bueren Kanal\n",
    "    \"625165\":\"Atlas5x5_625_165.csv\", # Untersee, Thunersee\n",
    "    \"625170\":\"Atlas5x5_625_170.csv\", # Sundlauenen, Thunersee\n",
    "    \"550185\":\"Atlas5x5_550_185.csv\", # Estavayer, Lac de Neuchatel\n",
    "    \"575210\":\"Atlas5x5_575_210.csv\", # Leuecherz, Bielersee\n",
    "    \"600200\":\"Atlas5x5_600_200.csv\", # Bern west, Aare\n",
    "    \"575245\":\"Atlas5x5_575_245.csv\"  # Saint-Ursanne, Aare\n",
    "}\n",
    "\n",
    "# convenience method to gather up all the files:\n",
    "def get_the_data(file_exts, a_dir, methods, this_method=\"csv\", myencoding=None):\n",
    "    wiw = {}\n",
    "    for k,v in file_exts.items():\n",
    "        if myencoding == None:\n",
    "            wiw.update({k:methods[this_method](F\"{a_dir}{v}\")})            \n",
    "        else:\n",
    "            wiw.update({k:methods[this_method](F\"{a_dir}{v}\",sep = \";\", encoding=myencoding)})\n",
    "    return wiw\n",
    "\n",
    "# use the get_the_data method to collect these files\n",
    "data_and_keys = get_the_data(d_files, data_2020, my_data_methods, this_method=\"csv\")\n",
    "watch_lists = get_the_data(w_lists, flora_h, my_data_methods, this_method=\"csv\")\n",
    "welt_sut =  get_the_data(ws_lists, flora_h_ws, my_data_methods, this_method=\"csv\", myencoding = \"utf-16\" )\n",
    "fivex =  get_the_data(fx_lists, flora_h_55, my_data_methods, this_method=\"csv\", myencoding = \"utf-16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-gabriel",
   "metadata": {},
   "source": [
    "Organization of the reference files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "suitable-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# housekeeping\n",
    "\n",
    "# housekeeping: make sure that each data set has the column \"species\", with the value species:\n",
    "watch_lists[\"list_2014\"][\"species\"] = watch_lists[\"list_2014\"].Latin\n",
    "watch_lists[\"under_sampled\"][\"species\"] = watch_lists[\"under_sampled\"].taxon\n",
    "watch_lists[\"red_list\"][\"species\"] = watch_lists[\"red_list\"].scientific_name\n",
    "\n",
    "# housekeeping: fx_lists['585220'] has one record in one column of one row stored as a string\n",
    "adf = fivex['585215'].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "conservative-playlist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a species slug (genus-species) to link data from across the survey and reference files. \n",
    "# This is necessary as some species columns have only \"Genus species\", some include subspecies, and some include the taxonomic reference.\n",
    "\n",
    "# function to make the species slugs\n",
    "def to_species_slug(x):\n",
    "    try: \n",
    "        int_data = x.split()\n",
    "        data = int_data[:2]\n",
    "        data = \"-\".join(data)\n",
    "        data = data.lower()\n",
    "    except:\n",
    "        data = \"none\"\n",
    "    return data\n",
    "\n",
    "# create a new column to hold the slug\n",
    "\n",
    "for element in [fivex, welt_sut, watch_lists]:\n",
    "    for the_data in element:\n",
    "        element[the_data]['species_slug'] = 'none'\n",
    "\n",
    "# make the species slug for all reference files\n",
    "\n",
    "for element in [fivex, welt_sut, watch_lists]:\n",
    "    for the_data in element:\n",
    "        element[the_data]['species_slug'] = element[the_data].species.map(lambda x: to_species_slug(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "arctic-doubt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add identifying columns to the reference datasets\n",
    "\n",
    "# add a column to identify the map source for the geographic data:\n",
    "\n",
    "for element in [fivex, welt_sut]:\n",
    "    for the_data in element:\n",
    "        element[the_data]['map'] = the_data\n",
    "        element[the_data]['spec_map'] = list(zip(element[the_data].species_slug,element[the_data].map))\n",
    "        \n",
    "# add a column to identify watch list:\n",
    "\n",
    "for element in [watch_lists]:\n",
    "    for the_data in element:\n",
    "        if the_data == \"list_2014\":\n",
    "            element[the_data]['watch_list'] = element[the_data][the_data]\n",
    "        else:\n",
    "            element[the_data]['watch_list'] = the_data\n",
    "\n",
    "# housekeeping: fill in nan values in the watchlist reference file.\n",
    "\n",
    "fill_nans = watch_lists[\"list_2014\"].copy()\n",
    "fill_nans = fill_nans.fillna(0)\n",
    "watch_lists.update({\"list_2014\":fill_nans[fill_nans.watch_list != 0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-estonia",
   "metadata": {},
   "source": [
    "Organization of the survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "diverse-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# housekeeping: clean up input errors in the sample data\n",
    "\n",
    "samples = data_and_keys['surveys'].copy()\n",
    "\n",
    "# dictionary of replacement values that are incorrect\n",
    "\n",
    "replacedict = {\n",
    "    'verbanum bonariensis ':'verbena bonariensis',\n",
    "    'medicago varia':'medicago sativa',\n",
    "    \"oenothera\":\"oenothera biennis\",\n",
    "    \"geranium pratens\":\"geranium pratense\",\n",
    "    \"senecio jacobaea\": \"jacobaea vulgaris\",\n",
    "    \"oenothera biennis \": \"oenothera biennis\",\n",
    "    \"oenothera biennis agg.\": \"oenothera biennis\",\n",
    "    \"solidalgo canadensis\": \"solidago canadensis\",\n",
    "    \"verbascum lynchitis\":\"verbascum lychnitis\",\n",
    "    \"verbascum negris\":\"verbascum nigrum\",\n",
    "    \"securigea varia\": \"securigera varia\",\n",
    "    \"melilotus officianalis\": \"melilotus officinalis\",\n",
    "    \"knautia maxima\": \"knautia dipsacifolia\",\n",
    "    \"hieracium aurantiacum\":\"pilosella aurantiaca\",\n",
    "    \"sysimbrium officinale\":\"sisymbrium officinale\",\n",
    "    \"geranium robertanium\":\"geranium robertianum\",\n",
    "    \"mycelis muralis\": \"lactuca muralis\",\n",
    "    \"calamintha-nepeta\":\"clinopodium nepeta\",\n",
    "    \"polygonum-persicaria\":\"persicaria maculosa\",\n",
    "    \"sorbus-aria\":\"aria edulis\",\n",
    "    \"taraxacum\": \"taraxacum officinale\"\n",
    "}\n",
    "\n",
    "# function to assign the correct value of the key is in the samples dictionary.\n",
    "\n",
    "def new_func(x,keys):\n",
    "    try:\n",
    "        data = keys[x]\n",
    "    except:\n",
    "        data = x\n",
    "    return data\n",
    "\n",
    "# apply the funtion to a copy of the surveys data set.\n",
    "\n",
    "samples[\"species2\"] = samples.sci.map(lambda x: new_func(x, replacedict))\n",
    "samples[\"species_slug\"] = samples.species2.map(lambda x: to_species_slug(x))\n",
    "\n",
    "# update the surveys dataset.\n",
    "\n",
    "data_and_keys.update({'surveys':samples})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "excited-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format dates in the sample dataset\n",
    "\n",
    "# function converts DD.MM.YYYY format to YYYY-MM-DD format, ignores if already in YYYY-MM-DD format\n",
    "\n",
    "def change_string(x):\n",
    "    try:\n",
    "        s_data = x.split('.')\n",
    "        data = s_data[::-1]\n",
    "        data = \"-\".join(data)\n",
    "    except:\n",
    "        print(\"no luck\")\n",
    "        data = x\n",
    "    \n",
    "    return data\n",
    "# applies the function to a column in the samples data frame\n",
    "\n",
    "samples['new_date'] = samples.date.map(lambda x: change_string(x))\n",
    "\n",
    "# function makes a timestamp out of the YYYY-MM-DD string.\n",
    "\n",
    "def make_timestamp(x):\n",
    "    try:        \n",
    "        data = dt.datetime.strptime(x, \"%Y-%m-%d\")        \n",
    "    except:        \n",
    "        data = 'no luck'\n",
    "    \n",
    "    return data\n",
    "\n",
    "# run the make_timestamp function and store the results in the samples dataframe.\n",
    "\n",
    "samples['stamp_date'] = samples.new_date.map(lambda x: make_timestamp(x))\n",
    "samples['date'] = samples.stamp_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fitting-citizenship",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make place name slugs\n",
    "\n",
    "#  change_place function turns \"place names 1\" into place-names-1\n",
    "def change_place(x):\n",
    "    data = x.split(\" \")\n",
    "    data = \"-\".join(data)\n",
    "    return data\n",
    "samples[\"place1\"] = samples.place.map(lambda x: change_place(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "shaped-thompson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>sci</th>\n",
       "      <th>name</th>\n",
       "      <th>species2</th>\n",
       "      <th>species_slug</th>\n",
       "      <th>new_date</th>\n",
       "      <th>stamp_date</th>\n",
       "      <th>place1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alleestrasse 1</td>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>11:09:04 AM</td>\n",
       "      <td>plantago lanceolata</td>\n",
       "      <td>plantain lancéolé</td>\n",
       "      <td>plantago lanceolata</td>\n",
       "      <td>plantago-lanceolata</td>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>alleestrasse-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alleestrasse 1</td>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>11:08:19 AM</td>\n",
       "      <td>centaurea nigra</td>\n",
       "      <td>centaurée noire</td>\n",
       "      <td>centaurea nigra</td>\n",
       "      <td>centaurea-nigra</td>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>alleestrasse-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alleestrasse 1</td>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>11:06:59 AM</td>\n",
       "      <td>plantago media</td>\n",
       "      <td>plantain moyen</td>\n",
       "      <td>plantago media</td>\n",
       "      <td>plantago-media</td>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>alleestrasse-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alleestrasse 1</td>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>11:06:05 AM</td>\n",
       "      <td>chenopodium album agg.</td>\n",
       "      <td>chénopode blanc</td>\n",
       "      <td>chenopodium album agg.</td>\n",
       "      <td>chenopodium-album</td>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>alleestrasse-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alleestrasse 1</td>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>11:05:18 AM</td>\n",
       "      <td>centaurea jacea agg.</td>\n",
       "      <td>centaurée jacée</td>\n",
       "      <td>centaurea jacea agg.</td>\n",
       "      <td>centaurea-jacea</td>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>alleestrasse-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            place       date         time                     sci  \\\n",
       "0  alleestrasse 1 2020-09-02  11:09:04 AM     plantago lanceolata   \n",
       "1  alleestrasse 1 2020-09-02  11:08:19 AM         centaurea nigra   \n",
       "2  alleestrasse 1 2020-09-02  11:06:59 AM          plantago media   \n",
       "3  alleestrasse 1 2020-09-02  11:06:05 AM  chenopodium album agg.   \n",
       "4  alleestrasse 1 2020-09-02  11:05:18 AM    centaurea jacea agg.   \n",
       "\n",
       "                name                species2         species_slug    new_date  \\\n",
       "0  plantain lancéolé     plantago lanceolata  plantago-lanceolata  2020-09-02   \n",
       "1    centaurée noire         centaurea nigra      centaurea-nigra  2020-09-02   \n",
       "2     plantain moyen          plantago media       plantago-media  2020-09-02   \n",
       "3    chénopode blanc  chenopodium album agg.    chenopodium-album  2020-09-02   \n",
       "4    centaurée jacée    centaurea jacea agg.      centaurea-jacea  2020-09-02   \n",
       "\n",
       "  stamp_date          place1  \n",
       "0 2020-09-02  alleestrasse-1  \n",
       "1 2020-09-02  alleestrasse-1  \n",
       "2 2020-09-02  alleestrasse-1  \n",
       "3 2020-09-02  alleestrasse-1  \n",
       "4 2020-09-02  alleestrasse-1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adopted-allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up redundant and unused column names\n",
    "\n",
    "# rename the place_slug column\n",
    "\n",
    "samples.rename(columns= {'place1':'place_slug'}, inplace=True)\n",
    "\n",
    "# remove the unnecessary columns for this analysis\n",
    "\n",
    "samples.drop(['species2', 'new_date', 'stamp_date', 'place', 'sci', 'time', 'name'] , inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bridal-jenny",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export samples to a .csv and a .json file for later use\n",
    "samples.to_csv(F\"resources/preprocessed/hd_samples_2020.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-andorra",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
